# CUDA Fix - –°–≤–æ–¥–∫–∞ —Ä–µ—à–µ–Ω–∏—è

## –ü—Ä–æ–±–ª–µ–º–∞
```
CUDA initialization: CUDA driver initialization failed
FATAL: CUT_REQUIRE_CUDA=1 but torch.cuda.is_available() is False
```

**–ü—Ä–∏—á–∏–Ω–∞:** PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –±–µ–∑ CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (CPU-only –≤–µ—Ä—Å–∏—è) –∏–ª–∏ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π CUDA.

## üéØ –†–µ—à–µ–Ω–∏–µ –∑–∞ 2 –º–∏–Ω—É—Ç—ã

### –ù–∞ GPU —Å–µ—Ä–≤–µ—Ä–µ:
```bash
cd /workspace/aporto
chmod +x upscale/vastai_deployment/*.sh
bash upscale/vastai_deployment/fix_torch_cuda.sh
systemctl restart vast-upscale.service
```

### –ò–ª–∏ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω—ã —á–µ—Ä–µ–∑ SSH:
```bash
cd /Users/igortkachenko/Downloads/aporto
chmod +x fix_cuda_remote.sh
./fix_cuda_remote.sh
```

## üìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

### –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã:
1. **`upscale/vastai_deployment/fix_torch_cuda.sh`**
   - –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç PyTorch —Å CUDA 12.1
   - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É GPU
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `bash upscale/vastai_deployment/fix_torch_cuda.sh [11.8|12.1]`

2. **`upscale/vastai_deployment/diagnose_cuda.sh`**
   - –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ CUDA –ø—Ä–æ–±–ª–µ–º
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤, PyTorch, GPU
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `bash upscale/vastai_deployment/diagnose_cuda.sh`

3. **`fix_cuda_remote.sh`** (–≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞)
   - –£–¥–∞–ª–µ–Ω–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ SSH
   - –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —à–∞–≥–∏
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `./fix_cuda_remote.sh`

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:
1. **`QUICK_FIX_CUDA.md`** - –±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–Ω–∞—á–Ω–∏—Ç–µ –æ—Ç—Å—é–¥–∞!)
2. **`CUDA_TROUBLESHOOTING.md`** - –ø–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ troubleshooting
3. **`upscale/vastai_deployment/README_CUDA_FIX.md`** - README –¥–ª—è GPU —Å–µ—Ä–≤–µ—Ä–∞
4. **`CUDA_FIX_SUMMARY.md`** - —ç—Ç–æ—Ç —Ñ–∞–π–ª (—Å–≤–æ–¥–∫–∞)

## üîß –ß—Ç–æ –¥–µ–ª–∞–µ—Ç fix_torch_cuda.sh?

```
1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã (nvidia-smi)
2. –£–¥–∞–ª—è–µ—Ç —Ç–µ–∫—É—â–∏–π PyTorch
3. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç PyTorch 2.4.1 —Å CUDA 12.1
4. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç torch.cuda.is_available()
5. –¢–µ—Å—Ç–∏—Ä—É–µ—Ç CUDA –æ–ø–µ—Ä–∞—Ü–∏–∏
6. –í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
```

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:

```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ
cd /workspace/aporto
bash upscale/vastai_deployment/diagnose_cuda.sh
```

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- ‚úÖ NVIDIA –¥—Ä–∞–π–≤–µ—Ä—ã (nvidia-smi)
- ‚úÖ –í–µ—Ä—Å–∏—è CUDA –≤ –¥—Ä–∞–π–≤–µ—Ä–∞—Ö
- ‚úÖ PyTorch –≤–µ—Ä—Å–∏—è –∏ CUDA support
- ‚úÖ –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
- ‚úÖ –î–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

### –í –ª–æ–≥–∞—Ö —Å–µ—Ä–≤–µ—Ä–∞:
```bash
tail -f /workspace/server.log
```
–î–æ–ª–∂–Ω–æ –±—ã—Ç—å:
```
CUDA OK: {'torch_installed': True, 'cuda_available': True, 'cuda_device_count': 1, ...}
```

### –í—Ä—É—á–Ω—É—é:
```bash
source .venv/bin/activate
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A')"
```
–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
```
CUDA: True
GPU: NVIDIA GeForce RTX 3090
```

## üö® –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

### 1. "nvidia-smi: command not found"
**–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –≤—ã–±—Ä–∞–Ω GPU instance –Ω–∞ Vast.ai, –∞ –Ω–µ CPU.

### 2. CUDA available: False –ø–æ—Å–ª–µ fix
**–†–µ—à–µ–Ω–∏–µ:** 
```bash
# –ü–æ–ø—Ä–æ–±—É–π—Ç–µ CUDA 11.8
bash upscale/vastai_deployment/fix_torch_cuda.sh 11.8
```

### 3. "CUDA out of memory"
**–†–µ—à–µ–Ω–∏–µ:**
```bash
systemctl restart vast-upscale.service
```

### 4. –ù–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç
**–†–µ—à–µ–Ω–∏–µ:** –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∞:
```bash
cd /workspace/aporto
rm -rf .venv
bash upscale/vastai_deployment/install.sh
```

## üìä –¢–∞–±–ª–∏—Ü–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

| –î—Ä–∞–π–≤–µ—Ä CUDA | PyTorch CUDA | –°—Ç–∞—Ç—É—Å |
|--------------|--------------|--------|
| 12.x         | 12.1         | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| 11.8+        | 12.1         | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å) |
| 11.x         | 11.8         | ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç |
| 10.x         | 12.1         | ‚ùå –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç |

## üéì –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å CUDA –¥—Ä–∞–π–≤–µ—Ä
nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å PyTorch CUDA
python -c "import torch; print(torch.__version__, torch.cuda.is_available())"

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å GPU –ø–∞–º—è—Ç—å
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä
systemctl restart vast-upscale.service

# –õ–æ–≥–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
tail -f /workspace/server.log

# –°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞
systemctl status vast-upscale.service
```

## üÜò –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ

–°–æ–±–µ—Ä–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

```bash
cd /workspace/aporto
bash upscale/vastai_deployment/diagnose_cuda.sh > ~/cuda_diagnostics.txt
tail -100 /workspace/server.log >> ~/cuda_diagnostics.txt
nvidia-smi >> ~/cuda_diagnostics.txt
```

–ò –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª `~/cuda_diagnostics.txt` –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

## üìñ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **PyTorch –≤–µ—Ä—Å–∏—è:** 2.4.1
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è CUDA:** 12.1 (fallback: 11.8)
- **–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –¥—Ä–∞–π–≤–µ—Ä:** 525.60.13
- **–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è Compute Capability:** 3.5

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [PyTorch CUDA installation](https://pytorch.org/get-started/locally/)
- [NVIDIA CUDA compatibility](https://docs.nvidia.com/deploy/cuda-compatibility/)
- [Vast.ai GPU instances](https://vast.ai/)
